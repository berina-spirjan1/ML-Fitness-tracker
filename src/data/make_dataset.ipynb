{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 9009 entries, 2019-01-11 15:08:05.200000 to 2019-01-20 17:33:27.800000\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   acc_x        9009 non-null   float64\n",
      " 1   acc_y        9009 non-null   float64\n",
      " 2   acc_z        9009 non-null   float64\n",
      " 3   gyr_x        9009 non-null   float64\n",
      " 4   gyr_y        9009 non-null   float64\n",
      " 5   gyr_z        9009 non-null   float64\n",
      " 6   label        9009 non-null   object \n",
      " 7   category     9009 non-null   object \n",
      " 8   participant  9009 non-null   object \n",
      " 9   set          9009 non-null   int64  \n",
      "dtypes: float64(6), int64(1), object(3)\n",
      "memory usage: 774.2+ KB\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Reading data from our CSV files that are stored inside this repository (single files)\n",
    "\n",
    "try: \n",
    "    single_file_accelerometer = pd.read_csv(\n",
    "        '../../data/raw/MetaMotion/A-bench-heavy2-rpe8_MetaWear_2019-01-11T16.10.08.270_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv')\n",
    "    single_file_gyroscope = pd.read_csv(\n",
    "        '../../data/raw/MetaMotion/A-bench-heavy2-rpe8_MetaWear_2019-01-11T16.10.08.270_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Files that you try to use are not available.\")\n",
    "\n",
    "# Reading all CVS files from data/raw/MetaMotion that we will use as a list later \n",
    "\n",
    "# Read all files that have csv extension if inside this repo the compiler finds some files that are not with this extension they \n",
    "# will be ignored\n",
    "\n",
    "files = glob('../../data/raw/MetaMotion/*.csv')\n",
    "\n",
    "\n",
    "data_path = '../../data/raw/MetaMotion/'\n",
    "\n",
    "first_file = files[0]\n",
    "\n",
    "def get_data_from_files(files):\n",
    "    accelerometer_data_frame = pd.DataFrame() # creating an empty data frame\n",
    "    gyroscope_data_frame = pd.DataFrame()\n",
    "\n",
    "    accelerometer_set = 1\n",
    "    gyroscope_set = 1\n",
    "\n",
    "    for file in files:\n",
    "        # Extract pieces of the file name e.g. A-bench-heavy2-rpe8_MetaWear_2019-01-11T16.10.08.270_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv and append \n",
    "        # it to the data frame\n",
    "        participant = file.split('-')[0].replace(data_path,'') # on this way we are updating existing path and getting the participate\n",
    "        exercise = file.split('-')[1]\n",
    "        category = file.split('-')[2].rstrip('123').rstrip('_MetaWear_2019') # with category we have the number of the set so we need to remove it\n",
    "\n",
    "        data_frame = pd.read_csv(file)\n",
    "\n",
    "        # We will extract three variables from the file name: participant: A, exercise: bench, category of sets(e.g. heavy)\n",
    "        data_frame['participant'] = participant # adding new columns inside the data frame\n",
    "        data_frame['exercise'] = exercise\n",
    "        data_frame['category'] = category\n",
    "\n",
    "        if 'Accelerometer' in file:\n",
    "            data_frame['set'] = accelerometer_set \n",
    "            accelerometer_set += 1\n",
    "            accelerometer_data_frame = pd.concat([accelerometer_data_frame,data_frame])\n",
    "    \n",
    "        if 'Gyroscope' in file:\n",
    "            data_frame['set'] = gyroscope_set\n",
    "            gyroscope_set += 1\n",
    "            gyroscope_data_frame = pd.concat([gyroscope_data_frame,data_frame])\n",
    "\n",
    "    # Working with date-times (epoch and time columns), epoch is the UTC date-time format from 1 January 1970 to today (in milliseconds),\n",
    "    # doesn't care in which time zone you are\n",
    "    accelerometer_data_frame.index = pd.to_datetime(accelerometer_data_frame[\"epoch (ms)\"],unit='ms')\n",
    "    gyroscope_data_frame.index = pd.to_datetime(gyroscope_data_frame[\"epoch (ms)\"],unit='ms')\n",
    "\n",
    "    # we need to delete duplicated columns \n",
    "\n",
    "    del accelerometer_data_frame['epoch (ms)']\n",
    "    del accelerometer_data_frame['time (01:00)']\n",
    "    del accelerometer_data_frame['elapsed (s)']\n",
    "\n",
    "    del gyroscope_data_frame['epoch (ms)']\n",
    "    del gyroscope_data_frame['time (01:00)']\n",
    "    del gyroscope_data_frame['elapsed (s)']\n",
    "\n",
    "    return accelerometer_data_frame, gyroscope_data_frame\n",
    "\n",
    "accelerometer_data_frame, gyroscope_data_frame = get_data_from_files(files)\n",
    "\n",
    "\n",
    "# Need to merge datasets into one\n",
    "\n",
    "dataset = pd.concat([accelerometer_data_frame.iloc[:,:3],gyroscope_data_frame],axis=1)\n",
    "\n",
    "dataset.dropna()\n",
    "\n",
    "dataset.columns = [\n",
    "    'acc_x',\n",
    "    'acc_y',\n",
    "    'acc_z',\n",
    "    'gyr_x',\n",
    "    'gyr_y',\n",
    "    'gyr_z',\n",
    "    'label',\n",
    "    'category',\n",
    "    'participant',\n",
    "    'set',\n",
    "]\n",
    "\n",
    "# Resample data (frequency conversion)\n",
    "\n",
    "sampling = {\n",
    "    'acc_x':'mean',\n",
    "    'acc_y':'mean',\n",
    "    'acc_z':'mean',\n",
    "    'gyr_x':'mean',\n",
    "    'gyr_y':'mean',\n",
    "    'gyr_z':'mean',\n",
    "    'label':'last',\n",
    "    'category':'last',\n",
    "    'participant':'last',\n",
    "    'set':'last',\n",
    "}\n",
    "\n",
    "\n",
    "dataset[:100].resample(rule=\"200ms\").apply(sampling)\n",
    "\n",
    "days = [g for n, g in dataset.groupby(pd.Grouper(freq=\"D\"))]\n",
    "\n",
    "data_resampled = pd.concat([df.resample(rule=\"200ms\").apply(sampling).dropna() for df in days])\n",
    "\n",
    "data_resampled['set'] = data_resampled['set'].astype('int')\n",
    "\n",
    "data_resampled.info()\n",
    "\n",
    "\n",
    "# Exporting dataset\n",
    "\n",
    "data_resampled.to_pickle('../../data/interim/01_data_processed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ecdebf77f2ee3a47348d003f751c63e810ca996c1c68d1179f338200fa83b34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
